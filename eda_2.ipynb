{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5f14207f-be28-4283-9314-1e02e715db8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fundamentos de Ciência de Dados\n",
    "## PPGI/UFRJ 2024.2\n",
    "### Profs Sergio Serra e Jorge Zavaleta\n",
    "### Aluno Ubirajara S. Santos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "21fc0eda-8216-4ae5-ba67-9a060afea2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prov\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4ac38fd8-c6aa-4138-ae54-2a103a3f52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './dados/saidas'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "38838849-a486-40fb-a8c1-35e945ee947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fontes de Dados\n",
    "data_sources = {\n",
    "     \"amostras_rochas_fluidos\": {\n",
    "        \"url\": \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos-amostras-de-rochas-e-fluidos/acervo-de-amostras/consolidacao-2023.zip\",\n",
    "        \"type\": \"zip\"},\n",
    "     \"setores_sirgas\": {\n",
    "        \"url\": \"https://www.gov.br/anp/pt-br/assuntos/exploracao-e-producao-de-oleo-e-gas/estudos-geologicos-e-geofisicos/arquivos-classificacao-de-modelos-exploratorios/setores-sirgas.zip\",\n",
    "        \"type\": \"zip\"},\n",
    "     \"blocos_exploratorios\": {\n",
    "        \"url\": \"https://gishub.anp.gov.br/geoserver/BD_ANP/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=BD_ANP%3ABLOCOS_EXPLORATORIOS_SIRGAS&maxFeatures=40000&outputFormat=SHAPE-ZIP\",\n",
    "        \"type\": \"zip\"},\n",
    "     \"campos_producao\": {\n",
    "        \"url\": \"https://gishub.anp.gov.br/geoserver/BD_ANP/ows?service=WFS&version=1.0.0&request=GetFeature&typeName=BD_ANP%3ACAMPOS_PRODUCAO_SIRGAS&maxFeatures=40000&outputFormat=SHAPE-ZIP\",\n",
    "        \"type\": \"zip\"},\n",
    "     \"reservas_nacionais_hc\": {\n",
    "        \"url\": \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-estatisticos/arquivos-reservas-nacionais-de-petroleo-e-gas-natural/tabela-dados-bar-2023.xlsx\",\n",
    "        \"type\": \"xlsx\"},\n",
    "     \"pocos_perfurados_2023\": {\n",
    "        \"url\": \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos-acervo-de-dados-tecnicos/pocos-publicos-2023.csv\",\n",
    "        \"type\": \"csv\"},\n",
    "     \"tabela_levantamentos_geoquimica\": {\n",
    "        \"url\": \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos-acervo-de-dados-tecnicos/tabela-levantamentos-geoquimicos.csv\",\n",
    "        \"type\": \"csv\"},\n",
    "     \"levantamento_sismico_2023\": {\n",
    "        \"url\": \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos-acervo-de-dados-tecnicos/sismicos-publicos-2023.csv\",\n",
    "        \"type\": \"csv\"},\n",
    "     \"tabela_pocos_2024\": {\n",
    "        \"url\": \"./dados/entradas/Tabela_pocos_2024_Novembro_24.csv\",\n",
    "        \"type\": \"csv\", \"sep\": \";\" ,\"encoding\": \"ANSI\"},\n",
    "     \"tabela_dados_geoquimica\": {\n",
    "        \"url\": \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos-acervo-de-dados-tecnicos/tabela-dados-geoquimicos.csv\",\n",
    "        \"type\": \"csv\",\n",
    "        \"header\": 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d2c3e5eb-413c-433b-ad53-5bfb214de691",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, datetime\n",
    "from prov.model import ProvDocument, Namespace\n",
    "from prov.dot import prov_to_dot\n",
    "from IPython.display import Image\n",
    "import plotly\n",
    "import graphviz\n",
    "import unicodedata\n",
    "\n",
    "def gerar_prov_outputs():\n",
    "    entity = \"EDA-PROV\"\n",
    "    output_file = f\"{entity}.png\"\n",
    "    try:\n",
    "        dot = prov_to_dot(doc_prov)\n",
    "        # Write to PNG\n",
    "        dot.write_png(output_file)\n",
    "        print(f\"Provenance graph generated successfully: {output_file}\")\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating provenance graph: {e}\")\n",
    "        # Save the DOT file for debugging\n",
    "        with open(\"debug.dot\", \"w\") as f:\n",
    "            f.write(dot.to_string())\n",
    "        print(\"Saved DOT file for debugging as 'debug.dot'.\")\n",
    "   \n",
    "        \n",
    "    #Gerando a Serialização - Output XML\n",
    "    doc_prov.serialize(entity + \".xml\", format='xml') \n",
    "\n",
    "    #Generating the Serialization - Output Turtle\n",
    "    doc_prov.serialize(entity + \".ttl\", format='rdf', rdf_format='ttl',encoding=\"utf-8\")\n",
    "    print(\"Provenance serialized as XML and TTL.\")\n",
    "\n",
    "def adding_namespaces(document_prov):\n",
    "    # Declaring namespaces for various prefixes used in the excution of Randon Walk Experiment\n",
    "    document_prov.add_namespace('void', 'http://vocab.deri.ie/void#')\n",
    "    document_prov.add_namespace('ufrj', 'https://www.ufrj.br')\n",
    "    document_prov.add_namespace('ex', 'http://example.org/')  # Exemplo de namespace\n",
    "    document_prov.add_namespace('prov', 'http://www.w3.org/ns/prov#')     # Padrões PROV\n",
    "    document_prov.add_namespace('foaf', 'http://xmlns.com/foaf/0.1/')     # Agentes FOAF\n",
    "    document_prov.add_namespace('ufrj-ppgi', 'http://www.ufrj.br/ppgi/')  # UFRJ PPGI\n",
    "    document_prov.add_namespace('anp', 'https://www.gov.br/anp/pt-br')    # ANP - Agência Nacional do Petróleo, Gás Natural e Biocombustíveis\n",
    "    document_prov.add_namespace('anp-dados_tec','https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/acervo-de-dados-tecnicos') # ANP - Acervo de Dados Técnicos \n",
    "    document_prov.add_namespace('petrobras','https://petrobras.com.br/')  # PETROBRAS\n",
    "    return document_prov\n",
    "\n",
    "\n",
    "def escape_label(text):\n",
    "    \"\"\"\n",
    "    Escapes special characters for Graphviz.\n",
    "    Encodes text to ASCII with XML character references.\n",
    "    \"\"\"\n",
    "    return text.encode(\"ascii\", \"xmlcharrefreplace\").decode()\n",
    "\n",
    "\n",
    "def create_agents(document_prov):\n",
    "    \n",
    "    #creating agents\n",
    "    dagnts={} #cria dic\n",
    "    dagnts[\"ag-anp\"] = document_prov.agent(\"anp:ANP\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":escape_label(\"Agência Nacional do Petróleo, Gás Natural e Biocombustíveis\")})\n",
    "    dagnts[\"ag-ufrj\"] = document_prov.agent(\"ufrj:UFRJ\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":escape_label(\"Universidade Federal do Rio de Janeiro\")})\n",
    "    dagnts[\"ag-ppgi\"] = document_prov.agent(\"ufrj:PPGI\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":escape_label(\"Programa de Pós Graduação em Informática\")})\n",
    "    dagnts[\"ag-greco\"] = document_prov.agent(\"ufrj:GRECO\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":escape_label(\"Grupo de Engenharia do Conhecimento\")})\n",
    "    dagnts[\"ag-author-ubirajara\"] = document_prov.agent(\"ufrj:Ubirajara\", {\"prov:type\":\"prov:Person\", \"foaf:name\":escape_label(\"Ubirajara Simões Santos\"), \"foaf:mbox\":\"ubirajas@hotmail.com\"})\n",
    "    dagnts[\"ag-author-sergio\"] = document_prov.agent(\"ufrj:Sergio\", {\"prov:type\":\"prov:Person\", \"foaf:name\":escape_label(\"Sergio Serra\"), \"foaf:mbox\":\"serra@ppgi.ufrj.br\"})\n",
    "    dagnts[\"ag-author-jorge\"] = document_prov.agent(\"ufrj:Jorge\", {\"prov:type\":\"prov:Person\", \"foaf:name\":escape_label(\"Jorge Zavaleta\"), \"foaf:mbox\":\"zavaleta@pet-si.ufrrj.br\"})\n",
    "    dagnts[\"ag-petrobras\"] = document_prov.agent(\"petrobras:Petrobras\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":escape_label(\"Petróleo Brasiliero S.A\")})\n",
    "    dagnts[\"ag-eda-ipynb\"] = document_prov.agent(\"ufrj:eda.ipynb\", {\"prov:type\":\"prov:SoftwareAgent\", \"foaf:name\":escape_label(\"eda.ipynb\"), \"prov:label\":escape_label(\"Notebook Python utilizado no trabalho\")})\n",
    "    return dagnts\n",
    "\n",
    "def associate_ufrj_agents(agents_dictionary):\n",
    "    agents_dictionary[\"ag-ppgi\"].actedOnBehalfOf(agents_dictionary[\"ag-ufrj\"])\n",
    "    agents_dictionary[\"ag-greco\"].actedOnBehalfOf(agents_dictionary[\"ag-ppgi\"])\n",
    "    agents_dictionary[\"ag-author-ubirajara\"].actedOnBehalfOf(agents_dictionary[\"ag-greco\"])\n",
    "    agents_dictionary[\"ag-author-ubirajara\"].actedOnBehalfOf(agents_dictionary[\"ag-petrobras\"])\n",
    "    agents_dictionary[\"ag-author-sergio\"].actedOnBehalfOf(agents_dictionary[\"ag-ppgi\"])\n",
    "    agents_dictionary[\"ag-author-jorge\"].actedOnBehalfOf(agents_dictionary[\"ag-ppgi\"])\n",
    "    agents_dictionary[\"ag-eda-ipynb\"].actedOnBehalfOf(agents_dictionary[\"ag-ppgi\"])\n",
    "    return agents_dictionary\n",
    "\n",
    "def create_initial_activities(document_prov):\n",
    "    #creating activities\n",
    "    #dataDownloadDatasets = datetime.datetime.strptime('29/11/24', '%d/%m/%y')\n",
    "    \n",
    "    dativs={}\n",
    "    dativs[\"act-create-ds\"] = document_prov.activity(\"anp:create-dataset\", None, None, {\"prov:label\":escape_label( \"Criação de datasets pela ANP\")})\n",
    "    #dativs[\"act-extract-ds\"] = document_prov.activity(\"ufrj:extract-dataset\")\n",
    "    dativs[\"act-create-ds-eda\"] = document_prov.activity(\"ufrj:create-ds-eda\", None, None, {\"prov:label\":escape_label( \"Criação de datasets para EDA\")})\n",
    "    \n",
    "    dativs[\"act-load-ds-eda\"] = document_prov.activity(\"ufrj:load-ds-eda\")\n",
    "    dativs[\"act-save-ipynb\"] = document_prov.activity(\"ufrj:save-ipynb\", None, None, {\"prov:label\":escape_label(\"Salvar notebook EDA\")})\n",
    "    return dativs\n",
    "\n",
    "def cria_entidades_iniciais(document_prov):\n",
    "    #creating entidades\n",
    "    dents={}\n",
    "    \n",
    "    # Entidade para amostras de rochas e fluidos\n",
    "    dents[\"ent-amostras-rochas-fluidos\"] = document_prov.entity('anp:amostras_rochas_fluidos', {'prov:label':escape_label('Dataset com amostras de rochas e fluidos'), 'prov:type': 'void:Dataset', 'prov:description':escape_label('Consolidado 2023 de amostras disponíveis.'), 'prov:format': 'zip' })\n",
    "    # Entidade para setores SIRGAS\n",
    "    dents[\"ent-setores-sirgas\"] = document_prov.entity('anp:setores_sirgas', {'prov:label':escape_label('Setores SIRGAS'), 'prov:type': 'void:Dataset', 'prov:description':escape_label('Modelos exploratórios em formato SIRGAS.'), 'prov:format': 'zip'})\n",
    "    # Entidade para blocos exploratórios\n",
    "    dents[\"ent-blocos-exploratorios\"] = document_prov.entity('anp:blocos_exploratorios', {'prov:label':escape_label( 'Blocos exploratórios'), 'prov:type': 'void:Dataset', 'prov:description':escape_label('Blocos exploratórios com dados geoespaciais.'), 'prov:format': 'zip'})\n",
    "    # Entidade para campos de produção\n",
    "    dents[\"ent-campos-producao\"] = document_prov.entity('anp:campos_producao', {'prov:label':escape_label( 'Campos de Produção'), 'prov:type': 'void:Dataset', 'prov:description':escape_label('Dados dos campos de produção em formato SIRGAS.'), 'prov:format': 'zip'})\n",
    "    # Entidade para reservas nacionais de hidrocarbonetos\n",
    "    dents[\"ent-reservas-nacionais-hc\"] = document_prov.entity('anp:reservas_nacionais_hc',{'prov:label':escape_label( 'Reservas Nacionais de Hidrocarbonetos'), 'prov:type': 'void:Dataset', 'prov:description':escape_label('Tabela com dados sobre reservas nacionais.'), 'prov:format': 'xlsx'})\n",
    "    # Entidade para poços perfurados (2023)\n",
    "    dents[\"ent-pocos-perfurados-2023\"] = document_prov.entity('anp:pocos_perfurados_2023',{'prov:label':escape_label( 'Poços perfurados - 2023'), 'prov:type': 'void:Dataset', 'prov:description':escape_label('CSV com os poços perfurados no ano de 2023.'), 'prov:format': 'csv'})\n",
    "    # Entidade para tabela de levantamentos geoquímicos\n",
    "    dents[\"ent-levantamento-geoquimica\"] = document_prov.entity('anp:levantamento_geoquimica',{'prov:label':escape_label( 'Tabela de levantamentos geoquímicos 20/04/2022'), 'prov:type': 'void:Dataset', 'prov:description':escape_label('Dados sobre levantamentos geoquímicos.'), 'prov:format': 'csv'})\n",
    "     # Entidade para tabela de dados geoquímicos\n",
    "    dents[\"ent-tabela-geoquimica\"] = document_prov.entity('anp:tabela_geoquimica',{'prov:label':escape_label( 'Tabela_dados_geoquimica 06/08/2021'), 'prov:type': 'void:Dataset', 'prov:description':escape_label('Dados geoquímicos.'), 'prov:format': 'csv'})\n",
    "     # Entidade para levantamento sísmico (2023)\n",
    "    dents[\"ent-levantamento-sismico-2023\"] = document_prov.entity('anp:levantamento_sismico_2023', {'prov:label':escape_label( 'Levantamento Sísmico - 2023'), 'prov:type': 'void:Dataset', 'prov:description':escape_label('CSV com dados de levantamentos sísmicos públicos.'), 'prov:format': 'csv'})\n",
    "    # Entidade para tabela de poços (2024)\n",
    "    dents[\"ent-tabela-pocos-2024\"] = document_prov.entity('anp:tabela_pocos_2024', {'prov:label':escape_label( 'Tabela de Poços - 2024'.encode(\"ascii\", \"xmlcharrefreplace\").decode()), 'prov:type': 'void:Dataset', 'prov:description':escape_label('Tabela CSV com dados atualizados de poços para 2024.'), 'prov:format': 'csv'})\n",
    "     # Entidade para ANP dados técnicos\n",
    "    dents[\"ent-anp-dados_tec-ds\"] = document_prov.entity('anp-dados_tec:dataset', {'prov:label':escape_label( 'ANP Dataset de Dados Técnicos'.encode(\"ascii\", \"xmlcharrefreplace\").decode()),'prov:type': 'void:Dataset','prov:description':escape_label('Dataset com dados técnicos disponíveis publicamente.'),'prov:format': 'csv'})\n",
    "    \n",
    "    # Entidade script python\n",
    "    dents[\"ent-eda-ipynb\"] = document_prov.entity('ufrj:eda-ipyn', {'prov:label':escape_label( \"Notebook Python utilizado no trabalho\".encode(\"ascii\", \"xmlcharrefreplace\").decode()), 'prov:type': 'foaf:Document'})\n",
    "    # Entidade Git\n",
    "    dents[\"ent-git-eda\"] = document_prov.entity('anp:github-eda', {'prov:label':escape_label( 'Repositorio Eba da ANP'.encode(\"ascii\", \"xmlcharrefreplace\").decode()), 'prov:type': 'prov:Collection'})\n",
    "    return dents\n",
    "\n",
    "def initial_association_agents_activities_entities(document_prov, dictionary_agents, dictionary_activities, dictionary_entities):\n",
    "    \n",
    "    #Associate activity of generate dataset with ANP agent\n",
    "    document_prov.wasAssociatedWith(dictionary_activities[\"act-create-ds\"], dictionary_agents[\"ag-anp\"])\n",
    "    \n",
    "    #Associating datasets with activities of generate eba datasets\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-amostras-rochas-fluidos\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-setores-sirgas\"], dictionary_activities[\"act-create-ds\"])    \n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-blocos-exploratorios\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-campos-producao\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-reservas-nacionais-hc\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-pocos-perfurados-2023\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-levantamento-geoquimica\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-tabela-geoquimica\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-levantamento-sismico-2023\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-tabela-pocos-2024\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-anp-dados_tec-ds\"], dictionary_activities[\"act-create-ds\"])\n",
    "    #document_prov.wasGeneratedBy(dictionary_entities[\"ent-dredfp\"], dictionary_activities[\"act-create-ds\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Associating ZIPs, XLSX, CSV com entities do dataset genérico\n",
    "    #document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2021-zip\"], dictionary_entities[\"ent-dredfp\"])  \n",
    "       \n",
    "    #associate activity of eda, com autor\n",
    "    document_prov.wasAssociatedWith(dictionary_activities[\"act-create-ds-eda\"], dictionary_agents[\"ag-author-ubirajara\"])   \n",
    "\n",
    "    #associate notebook agent with eba dataset\n",
    "    document_prov.wasAssociatedWith(dictionary_activities[\"act-create-ds-eda\"], dictionary_agents[\"ag-eda-ipynb\"])    \n",
    "    \n",
    "         \n",
    "    #associate eda github repository with store datasets activity\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-git-eda\"], dictionary_activities[\"act-save-ipynb\"])\n",
    "    \n",
    "    \n",
    "def initProvenance():\n",
    "    # criando um documento vazio de proveniência\n",
    "    global doc_prov, dict_agents, dict_activities, dict_entities\n",
    "    \n",
    "    doc_prov = ProvDocument()\n",
    "\n",
    "    #creating namespacing of provenabce document\n",
    "    doc_prov = adding_namespaces(doc_prov)\n",
    "    \n",
    "    #create agents\n",
    "    #agents_dict = create_agents(doc_prov)\n",
    "\n",
    "    dict_agents = create_agents(doc_prov)\n",
    "    dict_activities = create_initial_activities(doc_prov)  # Ensure this function returns a dictionary\n",
    "    dict_entities = cria_entidades_iniciais(doc_prov)\n",
    "    \n",
    "    #creating agents hierarchy\n",
    "    #agents_dict = associate_ufrj_agents(agents_dict)\n",
    "    dict_agents = associate_ufrj_agents(dict_agents)\n",
    "    #create initial activities\n",
    "    #activities_dict = create_initial_activities(doc_prov)\n",
    "\n",
    "    #create initial entities\n",
    "    #entities_dict = cria_entidades_iniciais(doc_prov)\n",
    "    \n",
    "    #initial provenance associations\n",
    "    #initial_association_agents_activities_entities(doc_prov, agents_dict, activities_dict, entities_dict)\n",
    "    initial_association_agents_activities_entities(doc_prov, dict_agents, dict_activities, dict_entities)\n",
    "\n",
    "    return doc_prov, dict_agents, dict_activities, dict_entities\n",
    "    #return provenance objects\n",
    "    #return doc_prov, agents_dict, activities_dict, entities_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "66ffb913-8d8d-47e9-b7a3-3c2e9f98ed5a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import openpyxl\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import zipfile\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9b0c37d3-49e2-46df-a7b9-a71a92541577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_csv_from_zip(url, temp_dir=\"./dados/temp\"):\n",
    "    \"\"\"\n",
    "    Baixa, extrai e retorna os caminhos dos arquivos CSV contidos em um ZIP.\n",
    "    \"\"\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    csv_files = []\n",
    "\n",
    "    try:\n",
    "        # Baixar o arquivo ZIP\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Erro ao baixar o arquivo: {response.status_code}\")\n",
    "        \n",
    "        # Abrir o ZIP em memória e extrair\n",
    "        with zipfile.ZipFile(BytesIO(response.content)) as zf:\n",
    "            zf.extractall(temp_dir)\n",
    "            extracted_files = zf.namelist()\n",
    "\n",
    "        # Identificar e coletar arquivos CSV\n",
    "        for file in extracted_files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(temp_dir, file)\n",
    "                csv_files.append({\"name\": os.path.basename(file), \"path\": file_path})\n",
    "\n",
    "        if not csv_files:\n",
    "            raise ValueError(\"Nenhum arquivo CSV encontrado no ZIP.\")\n",
    "        \n",
    "        print(f\"Arquivos CSV extraídos: {[file['name'] for file in csv_files]}\")\n",
    "        return csv_files\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar ZIP: {e}\")\n",
    "        return None\n",
    "        \n",
    "def update_data_sources_with_zip(data_sources, source_name, temp_dir=\"./temp\"):\n",
    "    \"\"\"\n",
    "    Atualiza `data_sources` com os arquivos CSV extraídos de um ZIP.\n",
    "    \"\"\"\n",
    "    source = data_sources.get(source_name)\n",
    "    if not source or source.get(\"type\") != \"zip\":\n",
    "        print(f\"Fonte '{source_name}' não encontrada ou não é um ZIP.\")\n",
    "        return data_sources\n",
    "\n",
    "    url = source[\"url\"]\n",
    "    csv_files = extract_csv_from_zip(url, temp_dir=temp_dir)\n",
    "\n",
    "    if csv_files:\n",
    "        for i, csv_file in enumerate(csv_files):\n",
    "            new_source_name = f\"{source_name}_csv_{i+1}\"\n",
    "            data_sources[new_source_name] = {\n",
    "                \"url\": csv_file,\n",
    "                \"type\": \"csv\",\n",
    "                \"sep\": source.get(\"sep\", \";\"),\n",
    "                \"encoding\": source.get(\"encoding\", \"utf-8\"),\n",
    "                \"header\": source.get(\"header\", 0),\n",
    "                \"date_columns\": source.get(\"date_columns\", [])\n",
    "            }\n",
    "        print(f\"Data sources atualizados com os arquivos CSV de '{source_name}'.\")\n",
    "    return data_sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "df4ff600-8332-4879-b792-63dcc13dc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_source(source_name, data_sources):\n",
    "    \"\"\"\n",
    "    Carrega dados com base no nome da fonte e na configuração em data_sources.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com os dados carregados, ou None se houver erro.\n",
    "    \"\"\"\n",
    "    global doc_prov, dict_agents,  dict_activities, dict_entities  # Declare global variables\n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "\n",
    "    source = data_sources.get(source_name)\n",
    "    if not source:\n",
    "        print(f\"Fonte '{source_name}' não encontrada em data_sources.\")\n",
    "        return None\n",
    "\n",
    "    file_type = source.get(\"type\")\n",
    "    url = source.get(\"url\")\n",
    "    sep = source.get(\"sep\", \";\")  # Valor padrão para CSV\n",
    "    encoding = source.get(\"encoding\", \"utf-8\")  # Valor padrão para codificação\n",
    "    date_columns = source.get(\"date_columns\", [])  \n",
    "\n",
    "   # try:\n",
    "    if file_type == \"csv\":\n",
    "         # Caso específico para tabela_pocos_2024\n",
    "        if source_name == \"tabela_pocos_2024\":\n",
    "            df = pd.read_csv(url, encoding=\"ANSI\", sep=sep)\n",
    "        # Caso específico para tabela_dados_geoquimica\n",
    "        elif source_name == \"tabela_dados_geoquimica\":\n",
    "            df = pd.read_csv(url, sep=sep, encoding=encoding, header=1)  # Cabeçalho na segunda linha\n",
    "        else:\n",
    "            df = pd.read_csv(url, sep=sep, encoding=encoding, parse_dates=date_columns)\n",
    "    elif file_type == \"xlsx\":\n",
    "        df = pd.read_excel(url)\n",
    "    else:\n",
    "        print(f\"Tipo de arquivo '{file_type}' não suportado.\")\n",
    "        return None\n",
    "    print(f\"Dados carregados com sucesso para '{source_name}'.\")\n",
    "\n",
    "    # End execution time for provenance tracking\n",
    "    execEndTime = datetime.datetime.now()\n",
    "\n",
    "    # Criar atividade com horário de término da execução\n",
    "    activity_key = f\"act-carga-{source_name}\"\n",
    "    dict_activities[activity_key] = doc_prov.activity(f\"ufrj:carga_{source_name}\", execStartTime, execEndTime)\n",
    "\n",
    "    # Associar a atividade ao agente\n",
    "    doc_prov.wasAssociatedWith(dict_activities[activity_key], dict_agents[\"ag-eda-ipynb\"])\n",
    "    \n",
    "    # Associar a atividade com os dados carregados\n",
    "    entity_key = f\"ent-{source_name}\"\n",
    "    dict_entities[entity_key] = doc_prov.entity(f\"ufrj:{entity_key}\",{\"prov:label\":escape_label( f\"Dataset carregado: {source_name}\"),\"prov:type\": \"void:Dataset\",\"prov:generatedAtTime\": execEndTime.isoformat(),},)\n",
    "    doc_prov.wasGeneratedBy(dict_entities[entity_key], dict_activities[activity_key])\n",
    "\n",
    "    #generate dataframe entity and associate with entity\n",
    "    #dict_entities[\"ent-\"+source_name] = doc_prov.entity(\"eda:df_eda_\"+source_name, {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com carga do dado '+source_mame})\n",
    "    #doc_prov.wasGeneratedBy(dict_entities[\"ent-\"+source_name], dict_activities[\"act-carga-\"+source_name])\n",
    "    \n",
    "    return df\n",
    "   # except Exception as e:\n",
    "    #    print(f\"Erro ao carregar dados de '{source_name}': {e}\")\n",
    "     #   return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0c0ab2cc-cc26-432b-a2e3-b3f6e10faa81",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_pocos_orig = load_data_from_source(\"tabela_pocos_2024\", data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e93ead43-b565-4fa0-b0c7-fec6078bf061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pocos_orig.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "498bbbcd-bf7d-465c-97dc-0e853178826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sismica_2023_orig = load_data_from_source(\"levantamento_sismico_2023\", data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ee466c73-7e1a-43e8-a2a5-84e351f624af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sismica_2023_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a618a908-1dfa-41cb-b4c0-00d8236b489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lev_geoq_2022 = load_data_from_source(\"tabela_levantamentos_geoquimica\", data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b51f81e5-229e-4a00-bc95-a3fac7b27125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lev_geoq_2022.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d67b0050-2ad2-4ef5-87f5-d718b5df1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_geoq_2021 = load_data_from_source(\"tabela_dados_geoquimica\", data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9403b858-cbe0-47d4-ab1a-b0b95568ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_geoq_2021.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "61f6a3ec-34a9-44f1-baa9-bb932ec77e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_reservas = load_data_from_source(\"reservas_nacionais_hc\", data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "822a7910-cf2d-4218-9b97-c9fe126a8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_reservas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "98157ebb-b8b4-470c-b5c6-17b68710a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##df_amostras = load_data_from_source(\"amostras_rochas_fluidos\", data_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "897f1c6f-dc55-4f22-97fe-fe518fa45719",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data_sources = update_data_sources_with_zip(data_sources, \"amostras_rochas_fluidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d4b2965e-2314-4f82-bd13-56ed2262cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "373b39d0-6baf-47de-84d3-1e3e15fdd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eda_dataset():\n",
    "    global doc_prov, dict_agents, dict_activities, dict_entities\n",
    "\n",
    "    # Load datasets and associate with provenance\n",
    "    df_sismica_2023_orig = load_data_from_source(\"levantamento_sismico_2023\", data_sources)\n",
    "    df_pocos_orig = load_data_from_source(\"tabela_pocos_2024\", data_sources)\n",
    "    df_lev_geoq_2022 = load_data_from_source(\"tabela_levantamentos_geoquimica\", data_sources)\n",
    "    df_geoq_2021 = load_data_from_source(\"tabela_dados_geoquimica\", data_sources)\n",
    "    df_reservas = load_data_from_source(\"reservas_nacionais_hc\", data_sources)\n",
    "\n",
    "    # Debugging provenance dictionaries\n",
    "    print(\"Activities after data load:\", dict_activities.keys())\n",
    "    print(\"Entities after data load:\", dict_entities.keys())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b202d74b-9be4-42fc-a479-d11b9c9a40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provenance objects were declare in global scope, just to avoid pass as parameters to all methods\n",
    "#doc_prov, dict_agents , dict_activities, dict_entities = initProvenance() # 4 variaveis com acesso global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "281c37a4-6a78-4b70-ac95-3aed03f21d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agents: dict_keys(['ag-anp', 'ag-ufrj', 'ag-ppgi', 'ag-greco', 'ag-author-ubirajara', 'ag-author-sergio', 'ag-author-jorge', 'ag-petrobras', 'ag-eda-ipynb'])\n",
      "Activities: dict_keys(['act-create-ds', 'act-create-ds-eda', 'act-load-ds-eda', 'act-save-ipynb'])\n",
      "Entities: dict_keys(['ent-amostras-rochas-fluidos', 'ent-setores-sirgas', 'ent-blocos-exploratorios', 'ent-campos-producao', 'ent-reservas-nacionais-hc', 'ent-pocos-perfurados-2023', 'ent-levantamento-geoquimica', 'ent-tabela-geoquimica', 'ent-levantamento-sismico-2023', 'ent-tabela-pocos-2024', 'ent-anp-dados_tec-ds', 'ent-eda-ipynb', 'ent-git-eda'])\n",
      "Dados carregados com sucesso para 'levantamento_sismico_2023'.\n",
      "Dados carregados com sucesso para 'tabela_pocos_2024'.\n",
      "Dados carregados com sucesso para 'tabela_levantamentos_geoquimica'.\n",
      "Dados carregados com sucesso para 'tabela_dados_geoquimica'.\n",
      "Dados carregados com sucesso para 'reservas_nacionais_hc'.\n",
      "Activities after data load: dict_keys(['act-create-ds', 'act-create-ds-eda', 'act-load-ds-eda', 'act-save-ipynb', 'act-carga-levantamento_sismico_2023', 'act-carga-tabela_pocos_2024', 'act-carga-tabela_levantamentos_geoquimica', 'act-carga-tabela_dados_geoquimica', 'act-carga-reservas_nacionais_hc'])\n",
      "Entities after data load: dict_keys(['ent-amostras-rochas-fluidos', 'ent-setores-sirgas', 'ent-blocos-exploratorios', 'ent-campos-producao', 'ent-reservas-nacionais-hc', 'ent-pocos-perfurados-2023', 'ent-levantamento-geoquimica', 'ent-tabela-geoquimica', 'ent-levantamento-sismico-2023', 'ent-tabela-pocos-2024', 'ent-anp-dados_tec-ds', 'ent-eda-ipynb', 'ent-git-eda', 'ent-levantamento_sismico_2023', 'ent-tabela_pocos_2024', 'ent-tabela_levantamentos_geoquimica', 'ent-tabela_dados_geoquimica', 'ent-reservas_nacionais_hc'])\n",
      "Provenance graph generated successfully: EDA-PROV.png\n",
      "Provenance serialized as XML and TTL.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize provenance objects\n",
    "    global doc_prov, dict_agents, dict_activities, dict_entities\n",
    "    doc_prov, dict_agents, dict_activities, dict_entities = initProvenance()\n",
    "\n",
    "    # Check initialization\n",
    "    print(\"Agents:\", dict_agents.keys())\n",
    "    print(\"Activities:\", dict_activities.keys())\n",
    "    print(\"Entities:\", dict_entities.keys())\n",
    "\n",
    "    #executa\n",
    "    create_eda_dataset();\n",
    "    gerar_prov_outputs()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd642769-e0a8-46d6-be83-39ea12671be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a17b0-533c-4b78-8f2f-f14902322878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e8324-b2d1-4894-b4b1-4c6668f966d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d97b7-c25b-4d4c-b602-bb9049fccd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a1fac-9ef9-4fa7-9b3a-4fa0e3256199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56345402-fcaf-4913-9861-2dc9efcfbf48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6c990-9abc-4fc4-a1ae-68b420c3b49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2ee99-f1a9-47cb-82ea-52aa76d2a37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec94a2-98e4-427e-929d-081f710d6677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f506e37-92db-4a88-ab2b-203f80583d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c143ab9-8012-4232-b168-77a432c3bcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92298a26-a92d-4000-9b52-34e1f1c7a3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf1381-e1c6-407c-896f-4232e02f8e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55abba-9f5a-45a9-997a-d31ee4b51883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda23c4-7eaf-426c-aaec-04eacd62a1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
